#!/usr/local/bin/python3
import sys
import re
import textwrap
import requests
import bs4

redirect = re.compile('#REDIRECT\s+?\[\[(\w+)\]\]')

resubs = [
    (re.compile('<.+?>'), ''),
    (re.compile('{{.+?}}'), ''),
    (re.compile('\[\[(?P<only>[\w\s]*)\]\]'), '\g<only>'),
    (re.compile('\[\[.+?\|(?P<second>[a-zA-Z0-9 ]+?)\]\]'), '\g<second>'),
    (re.compile('\'+'), '\''),
        ]

def get_text(url):
    d = {'User-Agent': 'WebAPI/pscohn@gmail.com'}
    r = requests.get(url).text

def get_wiki_intro(query):
    url = 'http://en.wikipedia.org/w/api.php?format=xml&action=query&titles=%s&prop=revisions&rvprop=content&rvsection=0' % query
    get_text(url)
    search = re.search(redirect, str(r))
    if search is not None:
        main(search.group(1))
    else:
        q = query.replace('_',' ').replace('+', '\+').replace("'", '')
        restring = '\'\'\'' + q + '.*\n'
        textex = re.compile(restring, re.IGNORECASE)
        soup = bs4.BeautifulSoup(r)
        try:
            result = re.search(textex, soup.text).group(0)
        except AttributeError:
            print('nothing found')
            return
        soup = bs4.BeautifulSoup(result)
        result = soup.text
        for s in resubs:
            result = re.sub(s[0], s[1], result)
        for line in textwrap.wrap(result, width=100):
            print(line)


def main(query):
    if query == '':
        print('usage:\n\nhuh [query]')
        return
    else:
        get_wiki_intro(query)
        return

if __name__ == '__main__':
    sys.exit(main('_'.join(sys.argv[1:])))
